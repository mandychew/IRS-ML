{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c02b30c6-ceb3-468a-8759-fe070d3677b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-addons in /home/wingyip/cyberthon-data-science/lib/python3.8/site-packages (0.16.1)\n",
      "Requirement already satisfied: typeguard>=2.7 in /home/wingyip/cyberthon-data-science/lib/python3.8/site-packages (from tensorflow-addons) (2.13.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-addons\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, losses, optimizers, callbacks\n",
    "import tensorflow_addons as tfa\n",
    "import json\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f477d89-ebfb-40ea-8bc5-ec9433ef4669",
   "metadata": {},
   "source": [
    "# Load and label data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ff9e996-eb4d-4653-9734-7b51f666724a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-05-07 19:42:50--  http://sighan.cs.uchicago.edu/bakeoff2005/data/icwb2-data.zip\n",
      "Resolving sighan.cs.uchicago.edu (sighan.cs.uchicago.edu)... 128.135.164.125\n",
      "Connecting to sighan.cs.uchicago.edu (sighan.cs.uchicago.edu)|128.135.164.125|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 52640127 (50M) [application/zip]\n",
      "Saving to: ‘icwb2-data.zip’\n",
      "\n",
      "icwb2-data.zip      100%[===================>]  50.20M  1.05MB/s    in 37s     \n",
      "\n",
      "2022-05-07 19:43:32 (1.35 MB/s) - ‘icwb2-data.zip’ saved [52640127/52640127]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://sighan.cs.uchicago.edu/bakeoff2005/data/icwb2-data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbd210dc-5df9-4ab3-9ab0-108e25cbab52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  icwb2-data.zip\n",
      "   creating: icwb2-data/\n",
      "   creating: icwb2-data/doc/\n",
      "  inflating: icwb2-data/doc/instructions.txt  \n",
      "  inflating: icwb2-data/doc/result_instructions.txt  \n",
      "   creating: icwb2-data/gold/\n",
      "  inflating: icwb2-data/gold/as_testing_gold.txt  \n",
      "  inflating: icwb2-data/gold/as_testing_gold.utf8  \n",
      "  inflating: icwb2-data/gold/as_training_words.txt  \n",
      "  inflating: icwb2-data/gold/as_training_words.utf8  \n",
      "  inflating: icwb2-data/gold/cityu_test_gold.txt  \n",
      "  inflating: icwb2-data/gold/cityu_test_gold.utf8  \n",
      "  inflating: icwb2-data/gold/cityu_training_words.txt  \n",
      "  inflating: icwb2-data/gold/cityu_training_words.utf8  \n",
      "  inflating: icwb2-data/gold/msr_test_gold.txt  \n",
      "  inflating: icwb2-data/gold/msr_test_gold.utf8  \n",
      "  inflating: icwb2-data/gold/msr_training_words.txt  \n",
      "  inflating: icwb2-data/gold/msr_training_words.utf8  \n",
      "  inflating: icwb2-data/gold/pku_test_gold.txt  \n",
      "  inflating: icwb2-data/gold/pku_test_gold.utf8  \n",
      "  inflating: icwb2-data/gold/pku_training_words.txt  \n",
      "  inflating: icwb2-data/gold/pku_training_words.utf8  \n",
      "  inflating: icwb2-data/README       \n",
      "   creating: icwb2-data/scripts/\n",
      "  inflating: icwb2-data/scripts/mwseg.pl  \n",
      "  inflating: icwb2-data/scripts/score  \n",
      "   creating: icwb2-data/testing/\n",
      "  inflating: icwb2-data/testing/as_test.txt  \n",
      "  inflating: icwb2-data/testing/as_test.utf8  \n",
      "  inflating: icwb2-data/testing/cityu_test.txt  \n",
      "  inflating: icwb2-data/testing/cityu_test.utf8  \n",
      "  inflating: icwb2-data/testing/msr_test.txt  \n",
      "  inflating: icwb2-data/testing/msr_test.utf8  \n",
      "  inflating: icwb2-data/testing/pku_test.txt  \n",
      "  inflating: icwb2-data/testing/pku_test.utf8  \n",
      "   creating: icwb2-data/training/\n",
      "  inflating: icwb2-data/training/as_training.b5  \n",
      "  inflating: icwb2-data/training/as_training.utf8  \n",
      "  inflating: icwb2-data/training/cityu_training.txt  \n",
      "  inflating: icwb2-data/training/cityu_training.utf8  \n",
      "  inflating: icwb2-data/training/msr_training.txt  \n",
      "  inflating: icwb2-data/training/msr_training.utf8  \n",
      "  inflating: icwb2-data/training/pku_training.txt  \n",
      "  inflating: icwb2-data/training/pku_training.utf8  \n"
     ]
    }
   ],
   "source": [
    "!unzip icwb2-data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3aced3-fa36-44d5-882a-7a5bed8ea1c2",
   "metadata": {},
   "source": [
    "## Read saved dataset (only run if it exists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a34f6f85-6771-4708-b699-dd399df16aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tokenizer.pkl\", \"rb\") as tokenizer_file:\n",
    "    tokenizer = pickle.load(tokenizer_file)\n",
    "\n",
    "df = pd.read_csv(\"df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1073b46f-519d-4a8c-874d-f3b4f5199f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label(sentence):\n",
    "    labels = []\n",
    "    for i in range(1, len(sentence)):\n",
    "        if sentence[i-1] != \"\\u3000\": # trailing punctuation will be ignored if it is preceded by a space (which I assume to always be true)\n",
    "            if sentence[i] == \"\\u3000\":\n",
    "                labels.append(1)\n",
    "            else:\n",
    "                labels.append(0)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ea7fc29-17ac-4837-acca-645152eb20b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"icwb2-data/training/as_training.utf8\", names=[\"sentences_split\"])\n",
    "df[\"sentences\"] = df[\"sentences_split\"].str.replace(\"\\u3000\", \"\").str[:-1] # remove spaces + strip trailing punctuation\n",
    "df[\"labels\"] = df[\"sentences_split\"].map(label)\n",
    "df[\"labels_padded\"] = list(tf.keras.preprocessing.sequence.pad_sequences(df[\"labels\"],\n",
    "                                                                         value=0, # ignored during loss calculation\n",
    "                                                                         padding=\"pre\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce13d0f-7e8d-4400-890f-257009ce15ff",
   "metadata": {},
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "94c91ae3-ae35-4578-a2fe-effa175ebce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(char_level=True)\n",
    "tokenizer.fit_on_texts(df[\"sentences\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "490c9dea-44d8-47d8-b1ef-aa911f54e657",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sentences_word_indices\"] = tokenizer.texts_to_sequences(df[\"sentences\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "18aaedda-8f72-45c7-8c7c-95046d5bbd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sentences_padded\"] = list(tf.keras.preprocessing.sequence.pad_sequences(df[\"sentences_word_indices\"],\n",
    "                                                                            value=0, # masked by Embedding layer\n",
    "                                                                            padding=\"pre\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c194006d-2a27-4105-87c1-d71180b184f1",
   "metadata": {},
   "source": [
    "## Save tokenizer and DataFrame to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1910abb9-3c78-40cc-a21a-e7ec8168c000",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tokenizer.pkl\", \"wb\") as tokenizer_file:\n",
    "    pickle.dump(tokenizer, tokenizer_file)\n",
    "\n",
    "df.to_csv(\"df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e7ce0f-e6c1-45a2-938f-5779667d5563",
   "metadata": {},
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87df6cee-d691-4ebf-8061-33ea8b66acf8",
   "metadata": {},
   "source": [
    "## Define model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fc971b16-a8c7-4662-8a70-db580b4bef4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sentence_length = len(df[\"sentences_padded\"].iloc[0])\n",
    "vocab_size = len(json.loads(tokenizer.get_config()[\"word_counts\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5b30af-5c57-46b1-874d-b7e05860f995",
   "metadata": {},
   "source": [
    "### Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d7bf1a9f-40ae-4516-8d60-8dab9a0401b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-13 16:49:13.395013: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-13 16:49:13.807431: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-13 16:49:13.808532: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-13 16:49:13.819218: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-13 16:49:13.820583: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-13 16:49:13.821685: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-13 16:49:13.822701: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-13 16:49:15.886135: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-13 16:49:15.887233: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-13 16:49:15.888217: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-13 16:49:15.889291: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6665 MB memory:  -> device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:29:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 187)]             0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 187, 200)          1215400   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 187, 256)         336896    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 187, 256)         394240    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 187, 256)         394240    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense (Dense)               (None, 187, 64)           16448     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 187, 2)            130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,357,354\n",
      "Trainable params: 2,357,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "xIn = layers.Input(shape=(max_sentence_length,))\n",
    "x = layers.Embedding(input_dim=vocab_size,\n",
    "                     output_dim=200,\n",
    "                     mask_zero=True)(xIn)\n",
    "# merge forward and backward outputs by concatenating outputs along last dimension, NOT by averaging (potentially causes information loss)\n",
    "x = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(x)\n",
    "x = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(x)\n",
    "x = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(x)\n",
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "xOut = layers.Dense(2, activation=\"linear\")(x) # softmax is computed by loss function, so don't use activation=\"softmax\" here\n",
    "\n",
    "model = tf.keras.Model(xIn, xOut)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533ca21e-9125-4244-ad2e-aca9fbf1118c",
   "metadata": {},
   "source": [
    "### Unidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b13d9fb-bc3f-4284-bf0d-b1d44bce8ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-11 16:53:37.502209: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-11 16:53:37.950587: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-11 16:53:37.951700: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-11 16:53:37.962485: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-11 16:53:37.964018: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-11 16:53:37.965111: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-11 16:53:37.966130: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-11 16:53:41.583656: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-11 16:53:41.584279: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-11 16:53:41.584879: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-11 16:53:41.602067: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6665 MB memory:  -> device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:29:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 187)]             0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 187, 200)          1215400   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 187, 128)          168448    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 187, 128)          131584    \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 187, 128)          131584    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 187, 64)           8256      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 187, 2)            130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,655,402\n",
      "Trainable params: 1,655,402\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "xIn = layers.Input(shape=(max_sentence_length,))\n",
    "x = layers.Embedding(input_dim=vocab_size,\n",
    "                     output_dim=200,\n",
    "                     mask_zero=True)(xIn)\n",
    "# merge forward and backward outputs by concatenating outputs along last dimension, NOT by averaging (potentially causes information loss)\n",
    "x = layers.LSTM(128, return_sequences=True)(x)\n",
    "x = layers.LSTM(128, return_sequences=True)(x)\n",
    "x = layers.LSTM(128, return_sequences=True)(x)\n",
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "xOut = layers.Dense(2, activation=\"linear\")(x) # softmax is computed by loss function, so don't use activation=\"softmax\" here\n",
    "# xOut = layers.Flatten()(x)\n",
    "\n",
    "model = tf.keras.Model(xIn, xOut)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cce4b3d-7df3-41ab-b198-1624a6b9e648",
   "metadata": {},
   "source": [
    "### Multi-head attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320454c9-60e1-4e5c-8847-15a7266b8daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "xIn = layers.Input(shape=(max_sentence_length,))\n",
    "x = layers.Embedding(input_dim=vocab_size,\n",
    "                     output_dim=200,\n",
    "                     mask_zero=True)(xIn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec2b63d-19ec-4c7f-97d7-e7f86ad790e6",
   "metadata": {},
   "source": [
    "## Define custom masked loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "094bb4e9-662e-4761-b881-eea4e979df5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedSequenceLoss(losses.Loss):\n",
    "    def __init__(\n",
    "        self,\n",
    "        average_across_timesteps=False,\n",
    "        average_across_batch=False,\n",
    "        sum_over_timesteps=True,\n",
    "        sum_over_batch=True,\n",
    "        softmax_loss_function=None,\n",
    "        name=None,\n",
    "        reduction=None, # dummy arg so it can be used as custom object when loading saved model\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.opts = {\n",
    "            \"average_across_timesteps\": average_across_timesteps,\n",
    "            \"average_across_batch\": average_across_batch,\n",
    "            \"sum_over_timesteps\": sum_over_timesteps,\n",
    "            \"sum_over_batch\": sum_over_batch,\n",
    "            \"softmax_loss_function\": softmax_loss_function,\n",
    "            \"name\": name,\n",
    "        }\n",
    "    \n",
    "    def call(self, y_true, y_pred):\n",
    "        return tfa.seq2seq.sequence_loss(y_pred, y_true,\n",
    "                                         weights=tf.cast(y_pred._keras_mask, tf.float32) if hasattr(y_pred, \"_keras_mask\") else tf.ones(y_true.shape),\n",
    "                                         **self.opts)\n",
    "\n",
    "def binary_crossentropy_arg_names_changed(labels, logits):\n",
    "#     print(labels.numpy(), logits.numpy())\n",
    "    output = tf.nn.sigmoid_cross_entropy_with_logits(tf.cast(labels, tf.float32)[..., tf.newaxis], logits)\n",
    "    print(output)\n",
    "    return output\n",
    "#     return tf.keras.losses.binary_crossentropy(y_true=labels, y_pred=logits, from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f6a5d40b-9a8a-4e79-9874-70420c32300d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizers.Adam(learning_rate=1e-3),\n",
    "#               loss=MaskedSequenceLoss(softmax_loss_function=binary_crossentropy_arg_names_changed),\n",
    "#               loss=MaskedSequenceLoss(softmax_loss_function=tf.nn.sigmoid_cross_entropy_with_logits),\n",
    "              loss=MaskedSequenceLoss(),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b9210f-ea85-4c92-a209-5311b359f789",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "99802e09-6f80-4478-8c96-de554543bda5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "410/788 [==============>...............] - ETA: 7:57 - loss: 0.0173 - accuracy: 0.8576"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [44]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msentences_padded\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m          \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabels_padded\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m          \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m720\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m          \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m          \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m          \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m              \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mReduceLROnPlateau\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m              \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEarlyStopping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrestore_best_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m              \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModelCheckpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msaved-models\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43munidirectional-lstm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepoch\u001b[39;49m\u001b[38;5;132;43;01m{epoch}\u001b[39;49;00m\u001b[38;5;124;43m_valloss\u001b[39;49m\u001b[38;5;132;43;01m{val_loss:.4f}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_best_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m          \u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/cyberthon-data-science/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/cyberthon-data-science/lib/python3.8/site-packages/keras/engine/training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1379\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1380\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1381\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1382\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1383\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1384\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1385\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1386\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/cyberthon-data-science/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/cyberthon-data-science/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/cyberthon-data-science/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/cyberthon-data-science/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2954\u001b[0m   (graph_function,\n\u001b[1;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/cyberthon-data-science/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m     args,\n\u001b[1;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1858\u001b[0m     executing_eagerly)\n\u001b[1;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/cyberthon-data-science/lib/python3.8/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/cyberthon-data-science/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x=tf.stack(df[\"sentences_padded\"]),\n",
    "          y=tf.stack(df[\"labels_padded\"]),\n",
    "          batch_size=720,\n",
    "          epochs=1000,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[\n",
    "              callbacks.ReduceLROnPlateau(patience=10, verbose=1),\n",
    "              callbacks.EarlyStopping(patience=20, verbose=1, restore_best_weights=True),\n",
    "              callbacks.ModelCheckpoint(filepath=os.path.join(\"saved-models\", \"unidirectional-lstm\", \"epoch{epoch}_valloss{val_loss:.4f}\"), verbose=1, save_best_only=True),\n",
    "          ]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b70d8a7-5cbc-4453-aa09-62e06375bd27",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "32c66582-40fc-44df-9467-34d7453ede81",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-13 17:19:18.479087: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:20.295208: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:22.050232: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:22.088671: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:22.357560: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:23.272600: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:23.286487: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:23.345233: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:23.529230: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:23.596030: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:23.894767: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:24.608591: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:24.622919: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:24.918218: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:25.406226: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:25.421241: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:25.667570: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:25.690905: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:26.068576: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:26.562696: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:27.452591: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:27.467567: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:27.555117: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:27.598696: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:27.612506: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:27.711007: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:27.782367: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:27.796304: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:27.907156: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:27.922920: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:28.359257: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:28.416746: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:28.446767: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:28.460727: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:28.566555: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:28.581207: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:28.639729: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:28.845775: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:28.860197: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:29.043092: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:29.510841: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:29.732537: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:29.759592: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:29.773879: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:30.111730: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:30.311086: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:30.327090: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:30.353166: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:30.368400: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:30.510333: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:30.639876: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:31.074830: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:31.150096: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:31.200243: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:31.214257: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:31.729225: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:31.743548: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:34.692080: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:35.523108: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:35.537204: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:35.788364: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:35.807287: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:35.910393: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:35.987386: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:36.001653: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:36.027849: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:36.323252: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:36.337081: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:36.427747: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:36.441714: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:36.457406: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:36.470785: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:36.590207: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:36.604956: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:37.035875: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:37.050385: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:37.480762: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:37.494826: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:38.003276: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:38.017697: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:38.643839: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:38.660827: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:38.674275: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2022-05-13 17:19:38.744415: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'cond' has 5 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n"
     ]
    }
   ],
   "source": [
    "custom_objects = { \"MaskedSequenceLoss\": MaskedSequenceLoss }\n",
    "with tf.keras.utils.custom_object_scope(custom_objects):\n",
    "    model = tf.keras.models.load_model(\"saved-models/bidirectional-lstm/epoch8_valloss0.0042\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6d37c00c-ce23-4b1b-bcc7-00435757a5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_sentence(sentence, skip_array):\n",
    "    assert len(sentence) == len(skip_array)\n",
    "    segmented_sentence = \"\"\n",
    "    for i in range(len(sentence)):\n",
    "        segmented_sentence += sentence[i]\n",
    "        if skip_array[i] == 1:\n",
    "            segmented_sentence += \" \"\n",
    "    return segmented_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5868e66a-7dca-4a5a-bfe6-9d47daca6c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你 瞅 啥 ！ 瞅 你 咋 地 ！ 再 瞅 一 个 试 试 ！ 试 试 就 试 试 ！ '"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentences = [\n",
    "    \"公教学生是个具有高尚情操、坚韧个性，同时热爱生活，热爱学习，并且愿为人群服务的领袖、双语学者、与彬彬君子。\", # Fail\n",
    "    \"明天更有一場「希望大樹」締造最多雙胞胎集合挑戰金氏世界紀錄活動。\", # OK\n",
    "    \"張玨的這番話讓目前還在台大唸博士班的郭淑珍及她的雙胞胎妹妹郭淑玲感受最深\", # OK except that it splits 張玨\n",
    "    \"然而，就其思想倾向而言，它却是属于日本战后派的，是战后派文学的一个组成部分。\", # Fail. Output: '然 而 ， 就 其 思 想 倾 向而 言 ， 它 却是 属 于 日 本 战 后 派 的， 是 战 后 派 文 学 的一 个 组成 部分 。 '\n",
    "    \"如果說電影《遠離賭城》是尼可拉斯凱吉藝術成就上的轉捩點\", # OK except that it doesn't separate 如果說\n",
    "    \"吳宇森正計劃拍攝一部二次大戰的電影《Ｗｉｎｄｔａｌｋｅｒｓ》\", # OK (二次大戰 should not be separated)\n",
    "    \"雄立獅島式是炎黃萬世其無疆\",\n",
    "    \"你好我的名字是傑夫\",\n",
    "    \"不過成員練唱時投入的程度可不輸給一般專業合唱團\",\n",
    "    \"你他媽到底在說我什麼，你這個小婊子？我會讓你知道我畢業於海豹突擊隊班，我曾參與過無數次對基地組織的秘密突襲，並確認殺死了 300 多人。我接受過大猩猩戰爭的訓練，我是整個美國武裝部隊中的頂級狙擊手。你對我來說什麼都不是，只是另一個目標。我會用地球上從未見過的精確度把你他媽擦掉，記住我他媽的話。你認為你可以在互聯網上對我說那些狗屎嗎？再想想，混蛋。在我們說話的時候，我正在聯繫我在美國的秘密間諜網絡，你的 IP 正在被追踪，所以你最好為風暴做好準備，蛆蟲。這場風暴會摧毀你稱之為生命的可悲小東西。你他媽死定了，孩子。我可以在任何地方，任何時間，我可以用七百多種方式殺死你，而這只是我的徒手。我不僅在徒手格斗方面受過廣泛的訓練，而且我還可以使用美國海軍陸戰隊的整個武器庫，我會盡其所能地使用它來將你的悲慘屁股從大陸上抹去，你這個小混蛋。如果你能知道你那小小的“聰明”評論會給你帶來什麼樣的邪惡報應，也許你會忍住你的舌頭。但你不能，你沒有，現在你要付出代價，你這個該死的白痴。我會在你身上發火，你會淹死的。你他媽死定了，孩子。\"[:187],\n",
    "    \"你瞅啥！瞅你咋地！再瞅一个试试！试试就试试！\",\n",
    "]\n",
    "\n",
    "test_sentence = test_sentences[10]\n",
    "test_sentence_sequence = tokenizer.texts_to_sequences([test_sentence])[0]\n",
    "test_sentence_sequence_padded = tf.keras.preprocessing.sequence.pad_sequences([test_sentence_sequence],\n",
    "                                                                              maxlen=max_sentence_length)[0]\n",
    "\n",
    "actual_pred_start_idx = max_sentence_length - len(test_sentence)\n",
    "test_preds = model.predict(test_sentence_sequence_padded[tf.newaxis, ...])[0, actual_pred_start_idx:]\n",
    "probabilities = tf.nn.softmax(test_preds)\n",
    "skip_array = tf.argmax(probabilities, axis=-1)\n",
    "\n",
    "segment_sentence(test_sentence, skip_array)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cyberthon-data-science",
   "language": "python",
   "name": "cyberthon-data-science"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
