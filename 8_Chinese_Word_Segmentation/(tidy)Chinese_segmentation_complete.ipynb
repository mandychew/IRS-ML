{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MU7k0WUN7dPF"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.6.0 and strictly below 2.9.0 (nightly versions are not supported). \n",
            " The versions of TensorFlow you are currently using is 2.9.1 and is not supported. \n",
            "Some things might work, some things might not.\n",
            "If you were to encounter a bug, do not file an issue.\n",
            "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
            "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
            "https://github.com/tensorflow/addons\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "#import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qeGnxU-OYpwV",
        "outputId": "408d93ff-1c26-4e5d-e278-65743fa69524"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "USrS6My477ym"
      },
      "outputs": [],
      "source": [
        "#xdf = pd.read_csv('/content/drive/MyDrive/ML/Datasets/Chinese_segmentation/as_training.utf8', header=None, names=['raw_words'])\n",
        "#xfor_vocab = open('/content/drive/MyDrive/ML/Datasets/Chinese_segmentation/as_training.utf8')\n",
        "\n",
        "#testdf = pd.read_csv('/content/drive/MyDrive/ML/Datasets/Chinese_segmentation/as_test.utf8', header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WNxc9hWFYgi4"
      },
      "outputs": [],
      "source": [
        "xdf = pd.read_csv(r'as_training.utf8', header=None, names=['raw_words'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Mie5F4TgCjGk"
      },
      "outputs": [],
      "source": [
        "def spaceornot(line):\n",
        "  splace = []\n",
        "  listed = list(line)\n",
        "  for i, char in enumerate(listed):\n",
        "    if listed[i] == listed[-1]:\n",
        "      splace.append(1)\n",
        "    elif char == '\\u3000':\n",
        "      pass\n",
        "    elif listed[i + 1] == '\\u3000':\n",
        "      splace.append(1)\n",
        "    elif listed[i + 1] != '\\u3000':\n",
        "      splace.append(0)\n",
        "  return splace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "M1RHsgw8-heC",
        "outputId": "5f7efdf6-eac9-4673-cd2b-04d0b86636d9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nused data:\\ntrain_data: xseq\\ntrain_label: yactual\\n'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "yraw = xdf.copy()\n",
        "\n",
        "xtrain = pd.DataFrame(xdf['raw_words'].str.replace('\\u3000',''))   #could ignore last punctuation\n",
        "\n",
        "#tokening _input data\n",
        "tokenizer = Tokenizer(char_level=True, oov_token='<OOV>')\n",
        "        #dlist_sent = seriestolist(xtrain, 0)\n",
        "tokenizer.fit_on_texts(xtrain['raw_words'])\n",
        "word_index = tokenizer.word_index\n",
        "xtrain['sequenced_sent'] = tokenizer.texts_to_sequences(xtrain['raw_words'])\n",
        "X = pad_sequences(xtrain['sequenced_sent'], padding='post')\n",
        "\n",
        "#y_actual\n",
        "yraw['labels'] = yraw['raw_words'].map(spaceornot)\n",
        "Y = pad_sequences(yraw['labels'], padding='post')\n",
        "\n",
        "\n",
        "# alternatively, you can pass the padded arrays into the dataframe by converting it into a list using list()\n",
        "\"\"\"\n",
        "used data:\n",
        "train_data: xseq\n",
        "train_label: yactual\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "VNm4SbcZ3Jgu"
      },
      "outputs": [],
      "source": [
        "val_split = 0.75\n",
        "vsize = len(word_index)\n",
        "sentlen = len(X[0,:])\n",
        "em_dim = 256\n",
        "epol = 1000\n",
        "basize = 1024\n",
        "\n",
        "#callbacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "aky4VCs3Ks0M"
      },
      "outputs": [],
      "source": [
        "#splitting dataset\n",
        "spli = int(val_split * len(X))\n",
        "trainX, testX = X[:spli], X[spli:]\n",
        "trainY, testY = Y[:spli], Y[spli:]\n",
        "\n",
        "\n",
        "#possible to split in ~model~.fit() function too"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Ngt7nEm7h22X"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Custom Loss\n",
        "'''\n",
        "\n",
        "class MaskedSequenceLoss(tf.keras.losses.Loss):\n",
        "    def __init__(\n",
        "        self,\n",
        "        average_across_timesteps=False,\n",
        "        average_across_batch=False,\n",
        "        sum_over_timesteps=True,\n",
        "        sum_over_batch=True,\n",
        "        softmax_loss_function=None,\n",
        "        name=None,\n",
        "        reduction=None, # dummy arg so it can be used as custom object when loading saved model\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.opts = {\n",
        "            \"average_across_timesteps\": average_across_timesteps,\n",
        "            \"average_across_batch\": average_across_batch,\n",
        "            \"sum_over_timesteps\": sum_over_timesteps,\n",
        "            \"sum_over_batch\": sum_over_batch,\n",
        "            \"softmax_loss_function\": softmax_loss_function,\n",
        "            \"name\": name,\n",
        "        }\n",
        "    \n",
        "    def call(self, y_true, y_pred):\n",
        "        return tfa.seq2seq.sequence_loss(y_pred, y_true,\n",
        "                                         weights=tf.cast(y_pred._keras_mask, tf.float32) if hasattr(y_pred, \"_keras_mask\") else tf.ones(y_true.shape),\n",
        "                                         **self.opts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iL1QUTngMliB",
        "outputId": "c73a51eb-7b56-4330-9cc8-eee55cf7b57c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 188)]             0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 188, 256)          1557760   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 188, 512)         1050624   \n",
            " l)                                                              \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 188, 256)         656384    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense (Dense)               (None, 188, 128)          32896     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 188, 128)          0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 188, 64)           8256      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 188, 64)           0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 188, 64)           4160      \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 188, 64)           0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 188, 2)            130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,310,210\n",
            "Trainable params: 3,310,210\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "xin = Input((sentlen,))\n",
        "\n",
        "x = Embedding(vsize, em_dim, input_length=sentlen, mask_zero = True)(xin) #ignore padded zeros -> mask_zero = True\n",
        "x = Bidirectional(LSTM(256, return_sequences=True))(x)\n",
        "x = Bidirectional(LSTM(128, return_sequences=True))(x)\n",
        "\n",
        "x = Dense(128, activation='swish')(x)\n",
        "x = Dropout(0.7)(x)\n",
        "x = Dense(64, activation='swish')(x) \n",
        "x = Dropout(0.7)(x)\n",
        "x = Dense(64, activation='swish')(x) \n",
        "x = Dropout(0.7)(x)\n",
        "\n",
        "xout = Dense(2, activation='linear')(x)\n",
        "\n",
        "segcl = Model(xin, xout)\n",
        "segcl.compile(optimizer='adam', loss=MaskedSequenceLoss(), metrics=['accuracy'])\n",
        "segcl.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "dibiJmHx3rX3"
      },
      "outputs": [],
      "source": [
        "callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=10, factor=0.1, verbose=1),\n",
        "    tf.keras.callbacks.ModelCheckpoint('./best_models', monitor='val_acc', save_best_only=True)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQAuG_pJP1Hg",
        "outputId": "b89fffb0-5691-4194-9af2-dc7fa080bba4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n"
          ]
        },
        {
          "ename": "InternalError",
          "evalue": "Graph execution error:\n\nDetected at node 'gradients/cond_grad/gradients/cond/CudnnRNNV3_grad/CudnnRNNBackpropV3' defined at (most recent call last):\n    File \"c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\mandy\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"C:\\Users\\mandy\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\mandy\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 473, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\mandy\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 462, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\mandy\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 369, in dispatch_shell\n      await result\n    File \"C:\\Users\\mandy\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 664, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\mandy\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\ipkernel.py\", line 355, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\Users\\mandy\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\mandy\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 2863, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\mandy\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 2909, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\mandy\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\mandy\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3106, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\mandy\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3309, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\mandy\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3369, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\mandy\\AppData\\Local\\Temp\\ipykernel_3052\\2058280542.py\", line 1, in <cell line: 1>\n      segcl.fit(\n    File \"c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 889, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\functional.py\", line 458, in call\n      return self._run_internal_graph(\n    File \"c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\functional.py\", line 596, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\layers\\rnn\\bidirectional.py\", line 249, in __call__\n      return super(Bidirectional, self).__call__(inputs, **kwargs)\n    File \"c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\layers\\rnn\\bidirectional.py\", line 364, in call\n      y = self.forward_layer(forward_inputs,\n    File \"c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\layers\\rnn\\base_rnn.py\", line 515, in __call__\n      return super(RNN, self).__call__(inputs, **kwargs)\n    File \"c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\layers\\rnn\\lstm.py\", line 673, in call\n      runtime) = lstm_with_backend_selection(**normal_lstm_kwargs)\n    File \"c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\layers\\rnn\\lstm.py\", line 1184, in lstm_with_backend_selection\n      gru_lstm_utils.function_register(defun_gpu_lstm, **params)\n    File \"c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\layers\\rnn\\gru_lstm_utils.py\", line 246, in function_register\n      concrete_func.add_gradient_functions_to_graph()\nNode: 'gradients/cond_grad/gradients/cond/CudnnRNNV3_grad/CudnnRNNBackpropV3'\nFailed to call ThenRnnBackward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 512, 128, 1, 188, 1024, 128] \n\t [[{{node gradients/cond_grad/gradients/cond/CudnnRNNV3_grad/CudnnRNNBackpropV3}}]]\n\t [[Adam/gradients/PartitionedCall]] [Op:__inference_train_function_28724]",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\mandy\\Copy of OneDrive\\Github\\IRS-ML\\8_Chinese_Word_Segmentation\\(tidy)Chinese_segmentation_complete.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/mandy/Copy%20of%20OneDrive/Github/IRS-ML/8_Chinese_Word_Segmentation/%28tidy%29Chinese_segmentation_complete.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m segcl\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mandy/Copy%20of%20OneDrive/Github/IRS-ML/8_Chinese_Word_Segmentation/%28tidy%29Chinese_segmentation_complete.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     trainX, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mandy/Copy%20of%20OneDrive/Github/IRS-ML/8_Chinese_Word_Segmentation/%28tidy%29Chinese_segmentation_complete.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     trainY,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mandy/Copy%20of%20OneDrive/Github/IRS-ML/8_Chinese_Word_Segmentation/%28tidy%29Chinese_segmentation_complete.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     validation_data\u001b[39m=\u001b[39;49m(testX, testY),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mandy/Copy%20of%20OneDrive/Github/IRS-ML/8_Chinese_Word_Segmentation/%28tidy%29Chinese_segmentation_complete.ipynb#X14sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     epochs \u001b[39m=\u001b[39;49m epol,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mandy/Copy%20of%20OneDrive/Github/IRS-ML/8_Chinese_Word_Segmentation/%28tidy%29Chinese_segmentation_complete.ipynb#X14sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     batch_size \u001b[39m=\u001b[39;49m basize,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mandy/Copy%20of%20OneDrive/Github/IRS-ML/8_Chinese_Word_Segmentation/%28tidy%29Chinese_segmentation_complete.ipynb#X14sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     callbacks \u001b[39m=\u001b[39;49m callbacks\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mandy/Copy%20of%20OneDrive/Github/IRS-ML/8_Chinese_Word_Segmentation/%28tidy%29Chinese_segmentation_complete.ipynb#X14sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mandy/Copy%20of%20OneDrive/Github/IRS-ML/8_Chinese_Word_Segmentation/%28tidy%29Chinese_segmentation_complete.ipynb#X14sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m#you can use validation_split = True to split the data into val and train, instead of manual splitting\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mandy/Copy%20of%20OneDrive/Github/IRS-ML/8_Chinese_Word_Segmentation/%28tidy%29Chinese_segmentation_complete.ipynb#X14sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m#using tf.stack, you can pass the dataframe series into it directly\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mandy/Copy%20of%20OneDrive/Github/IRS-ML/8_Chinese_Word_Segmentation/%28tidy%29Chinese_segmentation_complete.ipynb#X14sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mandy/Copy%20of%20OneDrive/Github/IRS-ML/8_Chinese_Word_Segmentation/%28tidy%29Chinese_segmentation_complete.ipynb#X14sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39msegcl.fit(\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mandy/Copy%20of%20OneDrive/Github/IRS-ML/8_Chinese_Word_Segmentation/%28tidy%29Chinese_segmentation_complete.ipynb#X14sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mandy/Copy%20of%20OneDrive/Github/IRS-ML/8_Chinese_Word_Segmentation/%28tidy%29Chinese_segmentation_complete.ipynb#X14sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mandy/Copy%20of%20OneDrive/Github/IRS-ML/8_Chinese_Word_Segmentation/%28tidy%29Chinese_segmentation_complete.ipynb#X14sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[1;32mc:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "\u001b[1;31mInternalError\u001b[0m: Graph execution error:\n\nDetected at node 'gradients/cond_grad/gradients/cond/CudnnRNNV3_grad/CudnnRNNBackpropV3' defined at (most recent call last):\n    File \"c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\mandy\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"C:\\Users\\mandy\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\mandy\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 473, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\mandy\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 462, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\mandy\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 369, in dispatch_shell\n      await result\n    File \"C:\\Users\\mandy\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 664, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\mandy\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\ipkernel.py\", line 355, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\Users\\mandy\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\mandy\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 2863, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\mandy\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 2909, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\mandy\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\mandy\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3106, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\mandy\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3309, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\mandy\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3369, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\mandy\\AppData\\Local\\Temp\\ipykernel_3052\\2058280542.py\", line 1, in <cell line: 1>\n      segcl.fit(\n    File \"c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 889, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\functional.py\", line 458, in call\n      return self._run_internal_graph(\n    File \"c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\functional.py\", line 596, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\layers\\rnn\\bidirectional.py\", line 249, in __call__\n      return super(Bidirectional, self).__call__(inputs, **kwargs)\n    File \"c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\layers\\rnn\\bidirectional.py\", line 364, in call\n      y = self.forward_layer(forward_inputs,\n    File \"c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\layers\\rnn\\base_rnn.py\", line 515, in __call__\n      return super(RNN, self).__call__(inputs, **kwargs)\n    File \"c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\layers\\rnn\\lstm.py\", line 673, in call\n      runtime) = lstm_with_backend_selection(**normal_lstm_kwargs)\n    File \"c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\layers\\rnn\\lstm.py\", line 1184, in lstm_with_backend_selection\n      gru_lstm_utils.function_register(defun_gpu_lstm, **params)\n    File \"c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\layers\\rnn\\gru_lstm_utils.py\", line 246, in function_register\n      concrete_func.add_gradient_functions_to_graph()\nNode: 'gradients/cond_grad/gradients/cond/CudnnRNNV3_grad/CudnnRNNBackpropV3'\nFailed to call ThenRnnBackward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 512, 128, 1, 188, 1024, 128] \n\t [[{{node gradients/cond_grad/gradients/cond/CudnnRNNV3_grad/CudnnRNNBackpropV3}}]]\n\t [[Adam/gradients/PartitionedCall]] [Op:__inference_train_function_28724]"
          ]
        }
      ],
      "source": [
        "segcl.fit(\n",
        "    trainX, \n",
        "    trainY,\n",
        "    validation_data=(testX, testY),\n",
        "    epochs = epol,\n",
        "    batch_size = basize,\n",
        "    callbacks = callbacks\n",
        ")\n",
        "\n",
        "#you can use validation_split = True to split the data into val and train, instead of manual splitting\n",
        "#using tf.stack, you can pass the dataframe series into it directly\n",
        "'''\n",
        "segcl.fit(\n",
        "\n",
        ")\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, None, 188)]       0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, None, 64)          12096     \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, None, 64)          4160      \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, None, 64)          4160      \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, None, 64)          4160      \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, None, 188)         12220     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 36,796\n",
            "Trainable params: 36,796\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "segcl = tf.keras.models.load_model(\"8_saved_models/8_best_model_weights\")\n",
        "segcl.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "FGOEFsCHYgi-"
      },
      "outputs": [],
      "source": [
        "def splitter(sentences, text_split_indexes):\n",
        "    dat = pd.DataFrame(sentences, columns=['unsplit'])\n",
        "    splited = []\n",
        "    for i, sentence in enumerate(sentences):\n",
        "        split_sen = ''\n",
        "        for n, sply in enumerate(list(text_split_indexes[i])[:len(sentence)]):\n",
        "            split_sen += sentence[n]\n",
        "            if sply == 1:\n",
        "                split_sen += '\\u3000'\n",
        "\n",
        "        splited.append(split_sen)\n",
        "    dat['splited'] = pd.DataFrame(splited)\n",
        "\n",
        "    return dat\n",
        "\n",
        "def display(dataframe):\n",
        "    for i in range(len(dataframe.iloc[:,0])):\n",
        "        print('original sentence:  ' + dataframe.iloc[i, 0])\n",
        "        print('splitted sentence:  ' + dataframe.iloc[i, 1])\n",
        "        print('\\n')\n",
        "\n",
        "\n",
        "def display_with_correct(dataframe, correct):\n",
        "    for i in range(len(dataframe.iloc[:,0])):\n",
        "        print('original sentence:  ' + dataframe.iloc[i, 0])\n",
        "        print('splitted sentence:  ' + dataframe.iloc[i, 1])\n",
        "        print('actually sentence:  ' + correct.iloc[i, 0])\n",
        "        print('\\n')\n",
        "\n",
        "def entire(input):\n",
        "    input_list = []\n",
        "    input_list.append(input)\n",
        "    token = tokenizer.texts_to_sequences(input_list)\n",
        "    token = pad_sequences(token, padding='post', maxlen=sentlen)\n",
        "\n",
        "    pred = segcl.predict(token)\n",
        "    pred = tf.nn.softmax(pred)\n",
        "    pred = np.argmax(pred, axis=-1)\n",
        "\n",
        "    return display(splitter(input_list, pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Jul9jOdIYgi-"
      },
      "outputs": [],
      "source": [
        "input_sentences=[\n",
        "    '生日快樂',\n",
        "    '我的名字是',\n",
        "    '今天的天氣很不可思議',\n",
        "    '中文單詞',\n",
        "    '雪花飄飄北風蕭蕭',\n",
        "    'Google 的免費服務可即時在英語和 100 多種其他語言之間翻譯單詞、短語和網頁。'\n",
        "\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ocmcuySBYgi-"
      },
      "outputs": [],
      "source": [
        "input_sentences = list(xtrain.iloc[:10,0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "WzVTGrYPYxOd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, None, 188) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 188), dtype=tf.float32, name='input_3'), name='input_3', description=\"created by layer 'input_3'\"), but it was called on an input with incompatible shape (None, 188).\n",
            "1/1 [==============================] - 11s 11s/step\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "'numpy.int64' object is not iterable",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\mandy\\Copy of OneDrive\\Github\\IRS-ML\\8_Chinese_Word_Segmentation\\(tidy)Chinese_segmentation_complete.ipynb Cell 17\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mandy/Copy%20of%20OneDrive/Github/IRS-ML/8_Chinese_Word_Segmentation/%28tidy%29Chinese_segmentation_complete.ipynb#X22sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m text_predictions \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39msoftmax(text_predictions)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mandy/Copy%20of%20OneDrive/Github/IRS-ML/8_Chinese_Word_Segmentation/%28tidy%29Chinese_segmentation_complete.ipynb#X22sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m text_predictions \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(text_predictions, axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/mandy/Copy%20of%20OneDrive/Github/IRS-ML/8_Chinese_Word_Segmentation/%28tidy%29Chinese_segmentation_complete.ipynb#X22sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m org_data \u001b[39m=\u001b[39m splitter(input_sentences, text_predictions)\n",
            "\u001b[1;32mc:\\Users\\mandy\\Copy of OneDrive\\Github\\IRS-ML\\8_Chinese_Word_Segmentation\\(tidy)Chinese_segmentation_complete.ipynb Cell 17\u001b[0m in \u001b[0;36msplitter\u001b[1;34m(sentences, text_split_indexes)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mandy/Copy%20of%20OneDrive/Github/IRS-ML/8_Chinese_Word_Segmentation/%28tidy%29Chinese_segmentation_complete.ipynb#X22sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, sentence \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(sentences):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mandy/Copy%20of%20OneDrive/Github/IRS-ML/8_Chinese_Word_Segmentation/%28tidy%29Chinese_segmentation_complete.ipynb#X22sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     split_sen \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/mandy/Copy%20of%20OneDrive/Github/IRS-ML/8_Chinese_Word_Segmentation/%28tidy%29Chinese_segmentation_complete.ipynb#X22sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mfor\u001b[39;00m n, sply \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mlist\u001b[39;49m(text_split_indexes[i])[:\u001b[39mlen\u001b[39m(sentence)]):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mandy/Copy%20of%20OneDrive/Github/IRS-ML/8_Chinese_Word_Segmentation/%28tidy%29Chinese_segmentation_complete.ipynb#X22sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         split_sen \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m sentence[n]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mandy/Copy%20of%20OneDrive/Github/IRS-ML/8_Chinese_Word_Segmentation/%28tidy%29Chinese_segmentation_complete.ipynb#X22sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         \u001b[39mif\u001b[39;00m sply \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
            "\u001b[1;31mTypeError\u001b[0m: 'numpy.int64' object is not iterable"
          ]
        }
      ],
      "source": [
        "token_sentences = tokenizer.texts_to_sequences(input_sentences)\n",
        "token_sentences = pad_sequences(token_sentences, padding='post', maxlen=sentlen)\n",
        "\n",
        "text_predictions = segcl.predict(token_sentences)\n",
        "text_predictions = tf.nn.softmax(text_predictions)\n",
        "text_predictions = np.argmax(text_predictions, axis=-1)\n",
        "\n",
        "org_data = splitter(input_sentences, text_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-7vD5bKYgi_",
        "outputId": "b2a2f020-6548-4de9-86c8-5f727cf26119"
      },
      "outputs": [],
      "source": [
        "display(org_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awjTDdlC-Slo",
        "outputId": "dbe38902-6bab-4b4d-c9a4-aff6aabc30ba"
      },
      "outputs": [],
      "source": [
        "entire('雪花飄飄北風蕭蕭')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#done"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Chinese_segmentation_complete.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "6425117d13823fa8044a2c07c859b613f2362d94b282c9a4162ba20339fd2c4d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
