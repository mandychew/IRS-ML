{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HuggingFace Crash Course\n",
    "Pipelines, Pretrained Model, Fine Tuning  \n",
    "Prerequisite:  `pip install transformers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mandy\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import TFAutoModelForSequenceClassification # for pytorch, same model but remove 'TF' in front\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Pipeline](https://huggingface.co/docs/transformers/main_classes/pipelines)  \n",
    "An easy way to use models for inference, e.g. sentiment analysis, image classification, object detection, question answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9997598528862}]\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline('sentiment-analysis')\n",
    "\n",
    "# feeding a sample text through pipeline\n",
    "result = classifier('We are very happy to show you the HuggingFace Transformers Library.')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 'POSITIVE', 'score': 0.9997598528862}\n",
      "{'label': 'NEGATIVE', 'score': 0.5308609008789062}\n"
     ]
    }
   ],
   "source": [
    "# feeding a list of text through pipeline\n",
    "X_train = [\"We are very happy to show you the HuggingFace Transformers Library.\", \"We hope you don't hate it.\"]\n",
    "results = classifier(X_train)\n",
    "\n",
    "for result in results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a specific model in pipeline\n",
    "[AutoModels documentation](https://huggingface.co/transformers/v3.0.2/model_doc/auto.html)  \n",
    "- for pytorch, `import AutoModelForSequenceClassification from transformers`\n",
    "- for tensorflow, `import TFAutoModelForSequenceClassification from transformers`  \n",
    "\n",
    "[AutoTokenizer documentation](https://huggingface.co/transformers/v3.0.2/model_doc/auto.html#autotokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'bert-base-uncased'\n",
    "\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "classifier1 = pipeline('sentiment-analysis', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Model and Tokenizer without pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 570/570 [00:00<00:00, 285kB/s]\n",
      "Downloading: 100%|██████████| 511M/511M [00:17<00:00, 29.8MB/s] \n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Downloading: 100%|██████████| 28.0/28.0 [00:00<00:00, 14.0kB/s]\n",
      "Downloading: 100%|██████████| 226k/226k [00:00<00:00, 312kB/s] \n",
      "Downloading: 100%|██████████| 455k/455k [00:01<00:00, 372kB/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 2057, 2024, 2200, 3407, 2000, 2265, 2017, 1996, 17662, 12172, 19081, 3075, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "Token ID 101 and 102 are the beginning and end of string tokens\n"
     ]
    }
   ],
   "source": [
    "model_name = 'bert-base-uncased'\n",
    "\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "token_ids = tokenizer(\"We are very happy to show you the HuggingFace Transformers Library.\")\n",
    "print(token_ids)\n",
    "print('In input_ids, tokens 101 and 102 are the beginning and end of string tokens')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [PreTrainedTokenizer documentation](https://huggingface.co/transformers/v3.0.2/main_classes/tokenizer.html#transformers.PreTrainedTokenizer) for parameter details.  \n",
    "Specifically for `return_tensors` parameter: click [here](https://huggingface.co/docs/transformers/main_classes/tokenizer#transformers.PreTrainedTokenizer.__call__.return_tensors)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': <tf.Tensor: shape=(2, 15), dtype=int32, numpy=\n",
      "array([[  101,  2057,  2024,  2200,  3407,  2000,  2265,  2017,  1996,\n",
      "        17662, 12172, 19081,  3075,  1012,   102],\n",
      "       [  101,  2057,  3246,  2017,  2123,  1005,  1056,  5223,  2009,\n",
      "         1012,   102,     0,     0,     0,     0]])>, 'token_type_ids': <tf.Tensor: shape=(2, 15), dtype=int32, numpy=\n",
      "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])>, 'attention_mask': <tf.Tensor: shape=(2, 15), dtype=int32, numpy=\n",
      "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]])>}\n"
     ]
    }
   ],
   "source": [
    "X_train = [\"We are very happy to show you the HuggingFace Transformers Library.\", \"We hope you don't hate it.\"]\n",
    "\n",
    "batch = tokenizer(X_train, padding=True, truncation=True, max_length=512, return_tensors='tf')\n",
    "print(batch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6425117d13823fa8044a2c07c859b613f2362d94b282c9a4162ba20339fd2c4d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
